{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e85f72e1-2069-4c4e-85ff-97d1306e4e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import SnowballStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b34f01-0593-411b-911f-dbfb57341762",
   "metadata": {},
   "source": [
    "First I split all the texts into tokens and reduce common words to stems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32f1dcae-2e9b-4e81-98cb-18b4410ab2d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [ad, sale, boost, time, warner, profit, quarte...\n",
       "1    [dollar, gain, on, greenspan, speech, the, dol...\n",
       "2    [yuko, unit, buyer, face, loan, claim, the, ow...\n",
       "3    [high, fuel, price, hit, ba, 's, profit, briti...\n",
       "4    [pernod, takeov, talk, lift, domecq, share, in...\n",
       "Name: tokens, dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stemmed Tokenization\n",
    "bbc = pd.read_csv(r\"C:\\Users\\m.al-zadid\\Downloads\\bbc.csv\")\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "def tokenize_stem(text):\n",
    "    tokens = word_tokenize(str(text))\n",
    "    stemmed_tokens = [stemmer.stem(word) for word in tokens]\n",
    "    return(stemmed_tokens)\n",
    "\n",
    "bbc[\"tokens\"] = bbc[\"text\"].apply(tokenize_stem)\n",
    "bbc[\"tokens\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3a5801-5eba-456e-a17c-3d88c5ccf0e6",
   "metadata": {},
   "source": [
    "Then I isolate $15\\%$ of the terms with lowest frequency and keep $85\\%$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb97b0a5-12d8-4edd-b54f-079dcb6d1794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping lowest frequency terms\n",
    "from collections import Counter \n",
    "\n",
    "bbc_counter = Counter()\n",
    "\n",
    "for article_tokens in bbc[\"tokens\"]:\n",
    "    bbc_counter.update(set(article_tokens))\n",
    "\n",
    "term_freq = pd.Series(bbc_counter)\n",
    "\n",
    "least_freq = term_freq.quantile(0.15)\n",
    "keep_terms = set(term_freq[term_freq > least_freq].index)\n",
    "\n",
    "bbc[\"tokens_filtered\"] = bbc[\"tokens\"].apply(\n",
    "    lambda article_tokens: [t for t in article_tokens \n",
    "                            if t in keep_terms]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7244c077-d88a-40da-955d-6f868d00cf75",
   "metadata": {},
   "source": [
    "Here I create the Document Term Matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d9d8ab1-1ea7-43af-a66c-ab9c1fbf80cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Document Term Matrix\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "docs_counts = [Counter(article_tokens) \n",
    "               for article_tokens in bbc[\"tokens_filtered\"]]\n",
    "\n",
    "vec = DictVectorizer(sparse = True)\n",
    "\n",
    "X = vec.fit_transform(docs_counts) # X is my DTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b30445c-6394-47a8-b345-022b81acb2e1",
   "metadata": {},
   "source": [
    "Finally, I print the feature vector of the words (with their corresponding frequencies) that appear 4 or more times in the 2121st article in the dataset. As Python uses 0-based indexing, the row-index will be 2120."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02b17131-3944-403d-a040-82448ec788d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('$', 4.0), (\"''\", 6.0), (',', 20.0), ('-', 5.0), ('.', 21.0), ('``', 7.0), ('a', 15.0), ('and', 10.0), ('appl', 6.0), ('as', 5.0), ('by', 5.0), ('comput', 6.0), ('for', 8.0), ('had', 4.0), ('in', 7.0), ('ipod', 8.0), ('it', 7.0), ('job', 7.0), ('mac', 8.0), ('mini', 4.0), ('mr', 4.0), ('new', 8.0), ('of', 9.0), ('said', 6.0), ('the', 26.0), ('to', 6.0), ('was', 4.0), ('will', 7.0), ('with', 4.0)]\n"
     ]
    }
   ],
   "source": [
    "# Create feature vector\n",
    "row = X[2120].toarray().ravel()\n",
    "condition = row >= 4\n",
    "\n",
    "words = vec.get_feature_names_out()\n",
    "\n",
    "result = [(words[i],row[i]) for i in range(len(words)) \n",
    "          if condition[i]]\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5caffd09-d871-437a-bca1-747f4500695f",
   "metadata": {},
   "source": [
    "Now I perform Chi-Square feature selection to the DTM to keep top 5000 terms that shows the strongest relationship with the article categories. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34f0e1f3-8cda-40aa-94a7-32c84b3f0b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2225, 5000)\n"
     ]
    }
   ],
   "source": [
    "# feature selection\n",
    "# chi-square\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "chi2_selector = SelectKBest(chi2, k=5000)\n",
    "X_chi2 = chi2_selector.fit_transform(X, bbc[\"category\"])\n",
    "\n",
    "print(X_chi2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2f8964-d2ae-4d49-a8a6-cba427ea5d85",
   "metadata": {},
   "source": [
    "Here I train and test with different combinations $(80/20, 75/25, 70/30)\\%$ of the data. And then I perform Naive Bayes and Logistic Regression to predict the article cateogries on test data by training the train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db36a9e4-b3c9-42cf-af12-a7c1f790a74b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\m.al-zadid\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# train-test, naive bayes, logistic regression\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support\n",
    "\n",
    "split = [0.2, 0.25, 0.3] #80-20, 75-25, 70-30\n",
    "y = bbc[\"category\"]\n",
    "\n",
    "for ts in split:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_chi2, bbc[\"category\"], test_size = ts, \n",
    "        stratify = y, random_state = 42\n",
    ")\n",
    "\n",
    "nb = MultinomialNB().fit(X_train, y_train)\n",
    "y_pred_nb = nb.predict(X_test)\n",
    "\n",
    "lr = LogisticRegression(multi_class = \"multinomial\", \n",
    "                        max_iter = 1000).fit(X_train, y_train)\n",
    "y_pred_lr = lr.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2183b83e-13e8-477a-a0e7-221373e0ae32",
   "metadata": {},
   "source": [
    "Here I create the confusion matrices for both models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1542e12a-e0da-4455-b2c5-2028804a7172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix for Naive Bayes:\n",
      "               business  entertainment  politics  sport  tech\n",
      "business            147              0         3      0     3\n",
      "entertainment         1            113         0      0     2\n",
      "politics              4              1       119      0     1\n",
      "sport                 0              1         2    151     0\n",
      "tech                  1              0         0      0   119\n",
      "\n",
      "Confusion Matrix for Logistic Regression:\n",
      "               business  entertainment  politics  sport  tech\n",
      "business            151              0         2      0     0\n",
      "entertainment         1            113         1      0     1\n",
      "politics              5              3       116      1     0\n",
      "sport                 1              0         0    153     0\n",
      "tech                  2              0         0      0   118\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "\n",
    "conf_matrix_nb = pd.DataFrame(confusion_matrix(\n",
    "    y_test, y_pred_nb, labels = nb.classes_), \n",
    "                              index = nb.classes_, \n",
    "                              columns = nb.classes_)\n",
    "\n",
    "conf_matrix_lr = pd.DataFrame(confusion_matrix(\n",
    "    y_test, y_pred_lr, labels = lr.classes_), \n",
    "                              index = lr.classes_, \n",
    "                              columns = lr.classes_)\n",
    "\n",
    "print('\\nConfusion Matrix for Naive Bayes:')\n",
    "print(conf_matrix_nb)\n",
    "print('\\nConfusion Matrix for Logistic Regression:')\n",
    "print(conf_matrix_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91fba924-0c23-4ff6-93e4-66d410e44696",
   "metadata": {},
   "source": [
    "Finally, I calculate precision and recall scores for both models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78ee8295-ff13-43b3-a729-42a9a1a412be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision and Recall per Class by Naive Bayes:\n",
      "               precision    recall\n",
      "business        0.960784  0.960784\n",
      "entertainment   0.982609  0.974138\n",
      "politics        0.959677  0.952000\n",
      "sport           1.000000  0.980519\n",
      "tech            0.952000  0.991667\n"
     ]
    }
   ],
   "source": [
    "# precision & recall scores for Naive Bayes\n",
    "prec, rec, _, _ = precision_recall_fscore_support(\n",
    "    y_test, y_pred_nb, \n",
    "    labels = nb.classes_, zero_division = 0\n",
    ")\n",
    "\n",
    "scores_nb = pd.DataFrame({'precision': prec, 'recall': rec}, \n",
    "                         index = nb.classes_)\n",
    "print('\\nPrecision and Recall per Class by Naive Bayes:')\n",
    "print(scores_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "910f1746-197c-42f5-8bab-56327443b756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision and Recall per Class by Logistic Regression:\n",
      "               precision    recall\n",
      "business        0.943750  0.986928\n",
      "entertainment   0.974138  0.974138\n",
      "politics        0.974790  0.928000\n",
      "sport           0.993506  0.993506\n",
      "tech            0.991597  0.983333\n"
     ]
    }
   ],
   "source": [
    "# precision & recall scores for Logistic Regression\n",
    "prec, rec, _, _ = precision_recall_fscore_support(\n",
    "    y_test, y_pred_lr, labels = lr.classes_, zero_division = 0\n",
    ")\n",
    "\n",
    "scores_lr = pd.DataFrame({'precision': prec, 'recall': rec}, \n",
    "                         index = lr.classes_)\n",
    "print('\\nPrecision and Recall per Class by Logistic Regression:')\n",
    "print(scores_lr)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
